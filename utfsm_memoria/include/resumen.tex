\chapter*{Resumen}
\addcontentsline{toc}{chapter}{Resumen}

%Esta memoria tratará sobre el uso de un tipo de estructura de indexación de textos conocido como el \textbf{arreglo de sufijos} y su derivado directo, el \textbf{arreglo LCP} para obtener de una cadena de proteínas la cantidad total de diferentes substrings de tamaño $k$ que variará entre 1 hasta 50, y para cada $k$ encontrar cuáles son los residuos que más se repiten. Para ello los archivos a utilizar para generar esta cadena son 4 que corresponden a las bases de datos de proteínas UniProt-SwissProt, UniProt-TrEMBL, EROP-Moscow y Homosapiens (extraído de UniProt-SwissProt). Se utilizarán 2 algoritmos para lograr este propósito, que construirán el arreglo de sufijos y el arreglo LCP de diferentes maneras y que tendrán en común el uso de la estructura conocida como \textbf{\textit{priority queue}} para guardar aquellos residuos que más se repitan.

Esta memoria tiene como finalidad buscar e identificar en archivos correspondientes a las bases de datos de proteínas UniProt-SwissProt, UniProt-TrEMBL, EROP-Moscow y Homosapiens (extraído de UniProt-SwissProt), la cantidad de diferentes fragmentos de proteínas de largo $k$ entre 1 hasta 50 e identificar cuáles son los fragmentos que más se repiten. Es importante esta tarea ya que la cantidad de proteínas que van apareciendo día a día crece y por lo mismo, es interesante considerar cuál es el porcentaje de diferentes fragmentos de péptidos que se abarca en la actualidad.

Para hacer esto se creó una cadena de texto generada de cada base de datos y en base a esta cadena se utilizó un tipo de estructura de indexación de textos conocido como el \textbf{arreglo de sufijos} y su derivado directo, el \textbf{arreglo LCP} para realizar las tareas mencionadas en el párrafo anterior. Se utilizarán 2 algoritmos para lograr este propósito, que construirán el arreglo de sufijos y el arreglo LCP de diferentes maneras y que tendrán en común el uso de la estructura conocida como \textbf{\textit{priority queue}} para guardar aquellos residuos que más se repitan.

Los resultados obtenidos para cada base de datos tienen en común que a medida que crece $k$, el porcentaje de diferentes fragmentos va disminuyendo y aquellos fragmentos que más se repiten siguen características físico-químicas similares.